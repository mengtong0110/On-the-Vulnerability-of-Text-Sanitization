import torch
import torch.nn as nn
from nltk.corpus import stopwords
from torch.optim import Adam, lr_scheduler
from torch.utils.data import Dataset, DataLoader
from transformers import BertModel, BertTokenizer
import os
import json
from tqdm import tqdm
import random


def load_categories(data_path1):
    categories_san = set() 
    with open(data_path1, 'r', encoding="utf8") as file:
        data_=json.load(file)
        for sample in data_:
            for i in range(len(sample[0])):
                if(sample[0][i] not in stop_words and sample[0][i] in p_dict and sample[1][i] in p_dict and sample[1][i] in R_dict):
                    categories_san.add(sample[1][i])
    return categories_san
eps_list=[8.0]

stop_words = set(stopwords.words('english'))

from task_set import task
for eps in eps_list:
    with open(f'./data/p_dict/glove_840B-300d_json/aggressive/eps_{eps}_top_20.txt','r') as dic:
        p_dict = json.load(dic)
    with open(f"./data/reverse_dict/re_{eps}_dict.txt",'r') as Re_file:
        R_dict=json.load(Re_file)
    data_path1 = f"./data/private_datasets/{eps}_{task}.txt"  
    categories_s=load_categories(data_path1=data_path1)
    categories_s=list(categories_s)
    random.shuffle(categories_s)
    categories_s=categories_s[:1000]
    with open('tokens_ctg.txt','w') as file:
        json.dump(categories_s,file)
