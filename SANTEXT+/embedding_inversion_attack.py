from task_set import task,eps_list,init_santext,init_eps
from SanText import SanText_top
import os
import json
from tqdm import tqdm
import random
random.seed(42)

with open('sen_words.txt','r') as sen_file:
    sen_words=json.load(sen_file) 

def load_sentence(data_path1,data_path2, categories_s):
    test_data = []
    train_data = []
    with open(data_path1, 'r', encoding="utf8") as file:
            data_=json.load(file)
    for san_token in  tqdm(categories_s,desc=f"{task} is loading"):           
        
            for sample in data_:
                for i in range(len(sample[0])):
                    if sample[1][i]==san_token and sample[0][i] in sen_words:
                        BY_c=[]
                        BY_t2=[]
                        BY_t1=[]
                        if(R_dict[sample[1][i]][0]==sample[0][i]):
                            label=1
                        else:
                            label=0
                        for j in range(len(sample[0])):
                            if len(sample[1][j])>=10:
                                continue
                            if(j<i):
                                BY_c.append(sample[1][j])
                                BY_t1.append(sample[1][j])
                            
                            elif(j>i):
                                BY_c.append(sample[1][j])
                                BY_t2.append(sample[1][j])
                            else:
                                BY_c.append(sample[1][j])
                        BY_c=" ".join(BY_c)
                        BY_t1=" ".join(BY_t1)
                        BY_t2=" ".join(BY_t2)
                        test_data.append([BY_c,BY_t1,BY_t2,sample[0][i],sample[1][i]])
    random.shuffle(test_data)
    test_data=test_data[:1000]
    return train_data, test_data

init_santext(task)
for eps in eps_list:
    init_eps(eps)
    with open(f'./data/attack_result/EMB_attack/{eps}_{task}.txt','w') as R_file:
        total_correct_predictions = 0
        total_evaluated_samples = 0
        data_path1 = f"./data/private_datasets/{eps}_{task}.txt"  
        data_path2 = f"./data/shadow_datasets/{eps}_{task}.txt"
        with open(f"./data/reverse_dict/re_{eps}_dict.txt",'r') as Re_file:
                R_dict=json.load(Re_file)
        with open(f"./data/Scores/Bayes_score/{eps}_{task}.txt",'r') as Rep_file:
                RP_dict=json.load(Rep_file)
        with open('tokens_ctg.txt','r') as file:
            categories_s=json.load(file)
        train_data, test_data= load_sentence(data_path1,data_path2,categories_s)
        print('test_num',len(test_data))
        for sample in tqdm(test_data,desc="Testing"):           
            raw_token=sample[3]
            attack_result= SanText_top(sample[4],1)
            if(raw_token in attack_result):
                total_correct_predictions += 1
            total_evaluated_samples += 1
        print(f"ASR of Embedding Inversion Attack with eps={eps} on {task} is: {total_correct_predictions/total_evaluated_samples:.4f}")
        R_file.write(f'ASR of Embedding Inversion Attack with eps={eps} on {task} is: {total_correct_predictions/total_evaluated_samples:.4f}')
