from tqdm import tqdm
import os
import unicodedata
from collections import Counter
from nltk.tokenize import word_tokenize

def word_normalize(text):
    """Resolve different type of unicode encodings."""
    return unicodedata.normalize('NFD', text)


def get_vocab_SST2(data_dir):
    vocab=Counter()
    for split in ['train','dev']:
        data_file_path=os.path.join(data_dir,split+".tsv")
        num_lines = sum(1 for _ in open(data_file_path))
        with open(data_file_path, 'r') as csvfile:
                next(csvfile)
                for line in tqdm(csvfile,total=num_lines-1):
                    line=line.strip().split("\t")
                    text = line[0]
                    tokenized_text = word_tokenize(text)
                    for token in tokenized_text:
                        vocab[token]+=1
    return vocab


def get_vocab_QNLI(data_dir):
    vocab=Counter()
    for split in ['train','dev']:
        data_file_path=os.path.join(data_dir,split+".tsv")
        num_lines = sum(1 for _ in open(data_file_path))
        with open(data_file_path, 'r') as csvfile:
            next(csvfile)
            for line in tqdm(csvfile,total=num_lines-1):
                line = line.strip().split("\t")
                text = line[2]
                tokenized_text = word_tokenize(text)
                for token in tokenized_text:
                    vocab[token]+=1
    vocab=vocab.most_common(15000)
    vocab = Counter(dict(vocab))
    return vocab


def get_vocab_AGNEWS(data_dir):
    vocab=Counter()
    for split in ['train']:
        data_file_path=os.path.join(data_dir,split+".tsv")
        num_lines = sum(1 for _ in open(data_file_path))
        with open(data_file_path, 'r') as csvfile:
            next(csvfile)
            for line in tqdm(csvfile,total=num_lines-1):
                line = line.strip()
                text = line
                tokenized_text = word_tokenize(text)
                for token in tokenized_text:
                    vocab[token]+=1
    vocab=vocab.most_common(15000)
    vocab = Counter(dict(vocab))
    return vocab


